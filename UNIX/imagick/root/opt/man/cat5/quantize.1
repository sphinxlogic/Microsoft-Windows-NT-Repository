


QUANTIZE(9)       MISC. REFERENCE MANUAL PAGES        QUANTIZE(9)



NNNNAAAAMMMMEEEE
     Quantize - ImageMagick's color reduction algorithm.

SSSSYYYYNNNNOOOOPPPPSSSSIIIISSSS
     ####iiiinnnncccclllluuuuddddeeee <<<<iiiimmmmaaaaggggeeee....hhhh>>>>

DDDDEEEESSSSCCCCRRRRIIIIPPPPTTTTIIIIOOOONNNN
     This document describes how _I_m_a_g_e_M_a_g_i_c_k performs color
     reduction on an image.  To fully understand this document,
     you should have a knowledge of basic imaging techniques and
     the tree data structure and terminology.

     For purposes of color allocation, an image is a set of _n
     pixels, where each pixel is a point in RGB space.  RGB space
     is a 3-dimensional vector space, and each pixel, _p9_i8,  is
     defined by an ordered triple of red, green, and blue
     coordinates, (_r9_i8, _g9_i8, _b9_i8).

     Each primary color component (red, green, or blue)
     represents an intensity which varies linearly from 0 to a
     maximum value, _c9_m_a_x8, which corresponds to full saturation of
     that color.  Color allocation is defined over a domain
     consisting of the cube in RGB space with opposite vertices
     at (0,0,0) and (_c9_m_a_x8,_c9_m_a_x8,_c9_m_a_x8).  _I_m_a_g_e_M_a_g_i_c_k requires _c9_m_a_x
8     = _2_5_5.

     The algorithm maps this domain onto a tree in which each
     node represents a cube within that domain.  In the following
     discussion, these cubes are defined by the coordinate of two
     opposite vertices: The vertex nearest the origin in RGB
     space and the vertex farthest from the origin.

     The tree's root node represents the the entire domain,
     (0,0,0) through (_c9_m_a_x8,_c9_m_a_x8,_c9_m_a_x8).  Each lower level in the
     tree is generated by subdividing one node's cube into eight
     smaller cubes of equal size.  This corresponds to bisecting
     the parent cube with planes passing through the midpoints of
     each edge.

     The basic algorithm operates in three phases:
     CCCCllllaaaassssssssiiiiffffiiiiccccaaaattttiiiioooonnnn,,,, RRRReeeedddduuuuccccttttiiiioooonnnn, and AAAAssssssssiiiiggggnnnnmmmmeeeennnntttt.  CCCCllllaaaassssssssiiiiffffiiiiccccaaaattttiiiioooonnnn
     builds a color description tree for the image.  RRRReeeedddduuuuccccttttiiiioooonnnn
     collapses the tree until the number it represents, at most,
     is the number of colors desired in the output image.
     AAAAssssssssiiiiggggnnnnmmmmeeeennnntttt defines the output image's color map and sets
     each pixel's color by reclassification in the reduced tree.

     CCCCllllaaaassssssssiiiiffffiiiiccccaaaattttiiiioooonnnn begins by initializing a color description
     tree of sufficient depth to represent each possible input
     color in a leaf.  However, it is impractical to generate a
     fully-formed color description tree in the classification
     phase for realistic values of _c9_m_a_x8.  If color components in



ImageMagick       Last change: 10 October 1992                  1






QUANTIZE(9)       MISC. REFERENCE MANUAL PAGES        QUANTIZE(9)



     the input image are quantized to _k-bit precision, so that
     _c9_m_a_x8 = _28_k9-_1, the tree would need _k levels below the root
     node to allow representing each possible input color in a
     leaf.  This becomes prohibitive because the tree's total
     number of nodes is

             R8 _k99_i=_1 _8_k
9     A complete tree would require 19,173,961 nodes for _k = _8,
     _c9_m_a_x8 = _2_5_5.  Therefore, to avoid building a fully populated
     tree, _I_m_a_g_e_M_a_g_i_c_k: (1) Initializes data structures for nodes
     only as they are needed; (2) Chooses a maximum depth for the
     tree as a function of the desired number of colors in the
     output image (currently _l_o_g9_48(_c_o_l_o_r_m_a_p _s_i_z_e)+_2).  A tree of
     this depth generally allows the best representation of the
     source image with the fastest computational speed and the
     least amount of memory.  However, the default depth is
     inappropriate for some images.  Therefore, the caller can
     request a specific tree depth.

     For each pixel in the input image, classification scans
     downward from the root of the color description tree.  At
     each level of the tree, it identifies the single node which
     represents a cube in RGB space containing the pixel's color.
     It updates the following data for each such node:

     nnnn911118::::  Number of pixels whose color is contained in the RGB
          cube which this node represents;

     nnnn922228::::  Number of pixels whose color is not represented in a
          node at lower depth in the tree;  initially,  _n9_28 = _0
          for all nodes except leaves of the tree.

     SSSS9rrrr8,,,, SSSS9gggg8,,,, SSSS9bbbb8::::
          Sums of the red, green, and blue component values for
          all pixels not classified at a lower depth.  The
          combination of these sums and _n9_28 will ultimately
          characterize the mean color of a set of pixels
          represented by this node.

     RRRReeeedddduuuuccccttttiiiioooonnnn repeatedly prunes the tree until the number of
     nodes with _n9_28  > _0 is less than or equal to the maximum
     number of colors allowed in the output image.  On any given
     iteration over the tree, it selects those nodes whose _n9_1
8     count is minimal for pruning and merges their color
     statistics upward.  It uses a pruning threshold, _n9_p8, to
     govern node selection as follows:

       n9p8 = 0
       while number of nodes with (n928 > 0) > required maximum
     number of colors
           prune all nodes such that n918 <= n9p


9ImageMagick       Last change: 10 October 1992                  2






QUANTIZE(9)       MISC. REFERENCE MANUAL PAGES        QUANTIZE(9)



           Set n9p8  to minimum n918  in remaining nodes

     When a node to be pruned has offspring, the pruning
     procedure invokes itself recursively in order to prune the
     tree from the leaves upward.  The values of _n9_28  _S9_r8, _S9_g8,  and
     _S9_b8 in a node being pruned are always added to the
     corresponding data in that node's parent.  This retains the
     pruned node's color characteristics for later averaging.

     For each node,  _n9_28 pixels exist for which that node
     represents the smallest volume in RGB space containing those
     pixel's colors.  When _n9_28  > _0 the node will uniquely define
     a color in the output image.  At the beginning of reduction,
     _n9_28 = _0  for all nodes except the leaves of the tree which
     represent colors present in the input image.

     The other pixel count, _n9_18,  indicates the total number of
     colors within the cubic volume which the node represents.
     This includes _n9_18 - _n9_28 pixels whose colors should be defined
     by nodes at a lower level in the tree.

     AAAAssssssssiiiiggggnnnnmmmmeeeennnntttt generates the output image from the pruned tree.
     The output image consists of two parts:  (1)  A color map,
     which is an array of color descriptions (RGB triples) for
     each color present in the output image; (2)  A pixel array,
     which represents each pixel as an index into the color map
     array.

     First, the assignment phase makes one pass over the pruned
     color description tree to establish the image's color map.
     For each node with _n9_28 > _0, it divides _S9_r8, _S9_g8, and _S9_b8 by _n9_28.
     This produces the mean color of all pixels that classify no
     lower than this node.  Each of these colors becomes an entry
     in the color map.

     Finally, the assignment phase reclassifies each pixel in the
     pruned tree to identify the deepest node containing the
     pixel's color.  The pixel's value in the pixel array becomes
     the index of this node's mean color in the color map.

     Empirical evidence suggests that distances in color spaces
     such as YUV, or YIQ correspond to perceptual color
     differences more closely than do distances in RGB space.
     These color spaces may give better results when color
     reducing an image.  Here the algorithm is as described
     except each pixel is a point in the alternate color space.
     For convenience, the color components are normalized to the
     range 0 to a maximum value, _c9_m_a_x8.  The color reduction can
     then proceed as described.

MMMMEEEEAAAASSSSUUUURRRRIIIINNNNGGGG CCCCOOOOLLLLOOOORRRR RRRREEEEDDDDUUUUCCCCTTTTIIIIOOOONNNN EEEERRRRRRRROOOORRRR




ImageMagick       Last change: 10 October 1992                  3






QUANTIZE(9)       MISC. REFERENCE MANUAL PAGES        QUANTIZE(9)



     Depending on the image, the color reduction error may be
     obvious or invisible.  Images with high spatial frequencies
     (such as hair or grass) will show error much less than
     pictures with large smoothly shaded areas (such as faces).
     This is because the high-frequency contour edges introduced
     by the color reduction process are masked by the high
     frequencies in the image.

     To measure the difference between the original and color
     reduced images (the total color reduction error),
     _I_m_a_g_e_M_a_g_i_c_k sums over all pixels in an image the distance
     squared in RGB space between each original pixel value and
     its color reduced value. _I_m_a_g_e_M_a_g_i_c_k prints several error
     measurements including the mean error per pixel, the
     normalized mean error, and the normalized maximum error.

     The normalized error measurement can be used to compare
     images.  In general, the closer the mean error is to zero
     the more the quantized image resembles the source image.
     Ideally, the error should be perceptually-based, since the
     human eye is the final judge of quantization quality.

     These errors are measured and printed when ----vvvveeeerrrrbbbboooosssseeee and
     ----ccccoooolllloooorrrrssss _a_r_e _s_p_e_c_i_f_i_e_d _o_n _t_h_e _c_o_m_m_a_n_d _l_i_n_e:

     mmmmeeeeaaaannnn eeeerrrrrrrroooorrrr ppppeeeerrrr ppppiiiixxxxeeeellll::::
          is the mean error for any single pixel in the image.

     nnnnoooorrrrmmmmaaaalllliiiizzzzeeeedddd mmmmeeeeaaaannnn ssssqqqquuuuaaaarrrreeee eeeerrrrrrrroooorrrr::::
          is the normalized mean square quantization error for
          any single pixel in the image.

          This distance measure is normalized to a range between
          0 and 1.  It is independent of the range of red, green,
          and blue values in the image.

     nnnnoooorrrrmmmmaaaalllliiiizzzzeeeedddd mmmmaaaaxxxxiiiimmmmuuuummmm ssssqqqquuuuaaaarrrreeee eeeerrrrrrrroooorrrr::::
          is the largest normalized square quantization error for
          any single pixel in the image.

          This distance measure is normalized to a range between
          0 and 1.  It is independent of the range of red, green,
          and blue values in the image.

SSSSEEEEEEEE AAAALLLLSSSSOOOO
     display(1), animate(1), mogrify(1), import(1), MIFF(5)

CCCCOOOOPPPPYYYYRRRRIIIIGGGGHHHHTTTT
     Copyright 1992 E. I. du Pont de Nemours & Company

     Permission to use, copy, modify, distribute, and sell this
     software and its documentation for any purpose is hereby



ImageMagick       Last change: 10 October 1992                  4






QUANTIZE(9)       MISC. REFERENCE MANUAL PAGES        QUANTIZE(9)



     granted without fee, provided that the above copyright
     notice appear in all copies and that both that copyright
     notice and this permission notice appear in supporting
     documentation, and that the name of E. I. du Pont de Nemours
     & Company not be used in advertising or publicity pertaining
     to distribution of the software without specific, written
     prior permission.  E. I. du Pont de Nemours & Company makes
     no representations about the suitability of this software
     for any purpose.  It is provided "as is" without express or
     implied warranty.

     E. I. du Pont de Nemours & Company disclaims all warranties
     with regard to this software, including all implied
     warranties of merchantability and fitness, in no event shall
     E. I. du Pont de Nemours & Company be liable for any
     special, indirect or consequential damages or any damages
     whatsoever resulting from loss of use, data or profits,
     whether in an action of contract, negligence or other
     tortious action, arising out of or in connection with the
     use or performance of this software.

AAAACCCCKKKKNNNNOOOOWWWWLLLLEEEEDDDDGGGGEEEEMMMMEEEENNNNTTTTSSSS
     Paul Raveling, USC Information Sciences Institute, for the
     original idea of using space subdivision for the color
     reduction algorithm.  With Paul's permission, this document
     is an adaptation from a document he wrote.

AAAAUUUUTTTTHHHHOOOORRRRSSSS
     John Cristy, E.I. du Pont de Nemours & Company Incorporated


























ImageMagick       Last change: 10 October 1992                  5



